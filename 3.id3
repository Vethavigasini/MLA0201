import csv
import math
import os

# --------------------------
# Read CSV
# --------------------------
def load_csv(path):
    with open(path, "r", newline="") as f:
        reader = csv.reader(f)
        header = next(reader)
        rows = []
        for r in reader:
            if r and any(cell.strip() for cell in r):
                rows.append([cell.strip() for cell in r])
    return header, rows


# --------------------------
# ID3 helpers
# --------------------------
def entropy(rows, target_index):
    counts = {}
    for r in rows:
        y = r[target_index]
        counts[y] = counts.get(y, 0) + 1

    total = len(rows)
    ent = 0.0
    for c in counts.values():
        p = c / total
        ent -= p * math.log2(p)
    return ent


def split_by_attribute(rows, attr_index):
    splits = {}
    for r in rows:
        key = r[attr_index]
        splits.setdefault(key, []).append(r)
    return splits


def information_gain(rows, attr_index, target_index):
    base = entropy(rows, target_index)
    splits = split_by_attribute(rows, attr_index)
    total = len(rows)

    remainder = 0.0
    for subset in splits.values():
        remainder += (len(subset) / total) * entropy(subset, target_index)

    return base - remainder


def majority_label(rows, target_index):
    counts = {}
    for r in rows:
        y = r[target_index]
        counts[y] = counts.get(y, 0) + 1
    return max(counts, key=counts.get)


def all_same_label(rows, target_index):
    first = rows[0][target_index]
    for r in rows:
        if r[target_index] != first:
            return False
    return True


# --------------------------
# Build ID3 tree
# Tree format:
#   {"attribute": attr_name, "nodes": {value: subtree}, "default": majority_label}
# or leaf: {"label": "Yes"}
# --------------------------
def id3(rows, header, attributes, target_index):
    # If all examples have same label -> leaf
    if all_same_label(rows, target_index):
        return {"label": rows[0][target_index]}

    # If no attributes left -> leaf with majority label
    if not attributes:
        return {"label": majority_label(rows, target_index)}

    # Choose best attribute (max information gain)
    gains = [(a, information_gain(rows, a, target_index)) for a in attributes]
    best_attr, best_gain = max(gains, key=lambda x: x[1])

    tree = {
        "attribute": header[best_attr],
        "nodes": {},
        "default": majority_label(rows, target_index)
    }

    splits = split_by_attribute(rows, best_attr)
    remaining_attrs = [a for a in attributes if a != best_attr]

    for attr_value, subset in splits.items():
        tree["nodes"][attr_value] = id3(subset, header, remaining_attrs, target_index)

    return tree


def predict(tree, header, sample_dict):
    # If leaf
    if "label" in tree:
        return tree["label"]

    attr = tree["attribute"]
    val = sample_dict.get(attr)

    # Unknown attribute value or missing -> default
    if val not in tree["nodes"]:
        return tree["default"]

    return predict(tree["nodes"][val], header, sample_dict)


def print_tree(tree, indent=""):
    if "label" in tree:
        print(indent + "→ " + str(tree["label"]))
        return

    print(indent + "[" + tree["attribute"] + "]")
    for v, subtree in tree["nodes"].items():
        print(indent + "  (" + str(v) + ")")
        print_tree(subtree, indent + "    ")
    print(indent + "  (default) → " + str(tree["default"]))


# --------------------------
# MAIN (auto-find PlayTennis.csv)
# --------------------------
filename = "PlayTennis.csv"
possible_paths = [
    filename,
    os.path.join(os.getcwd(), filename),
    os.path.join(os.path.expanduser("~"), "Downloads", filename),
    os.path.join(os.path.expanduser("~"), "Documents", filename),
    os.path.join(os.path.expanduser("~"), "Desktop", filename),
]

csv_path = None
for p in possible_paths:
    if os.path.exists(p):
        csv_path = p
        break

if csv_path is None:
    print("ERROR: PlayTennis.csv not found.")
    print("Put PlayTennis.csv in same folder OR Downloads/Documents/Desktop.")
    print("Checked paths:")
    for p in possible_paths:
        print(" -", p)
else:
    header, rows = load_csv(csv_path)
    target_index = len(header) - 1

    # attribute indices except target
    attributes = list(range(0, target_index))

    tree = id3(rows, header, attributes, target_index)

    print("Using dataset:", csv_path)
    print("\n--- ID3 Decision Tree ---")
    print_tree(tree)

    # ---- Classify a new sample (edit values if your CSV uses different words) ----
    # Example for classic dataset:
    new_sample = {
        "Outlook": "Sunny",
        "Temperature": "Cool",
        "Humidity": "High",
        "Wind": "Strong"
    }

    result = predict(tree, header, new_sample)
    print("\nNew Sample:", new_sample)
    print("Predicted Class (PlayTennis):", result)
